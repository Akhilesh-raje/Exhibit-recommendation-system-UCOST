# Gemma 2B Recommender System

âœ… **100% Complete & Working**

> High-level context now sits in the monorepo root `README.md` (**Subsystem Guides â†’ Gemma Recommender**). Keep this document focused on deep component details.

## ğŸ¯ Overview

This module provides multimodal exhibit recommendations using Gemma 2B with all available modalities:
- **Text**: names, descriptions, categories, tags
- **Images**: exhibit images via CLIP/ViT encoders
- **Metadata**: location (floor/x/y), average time, rating, features

## âœ… **Status: Fully Operational**

**The Gemma inference server is running and embeddings are built. The recommendation service is integrated and working.**

## ğŸ—ï¸ Architecture

### Multimodal Recommendation Pipeline

1. **Text Processing**: Extract and encode exhibit text features
2. **Image Encoding**: Use CLIP/ViT to encode exhibit images
3. **Metadata Fusion**: Combine location, time, rating, and feature metadata
4. **Gemma 2B Fine-tuning**: LoRA/QLoRA fine-tuned model for ranking
5. **FAISS Search**: Fast similarity search in embedding space
6. **Reranking**: Logistic reranker for final result quality

## ğŸ“ Directory Structure

```
gemma/
â”œâ”€â”€ data/                    # Training data, manifests, cached features
â”‚   â”œâ”€â”€ exhibits.csv        # Exhibit dataset
â”‚   â”œâ”€â”€ metadata.json       # Metadata definitions
â”‚   â””â”€â”€ training_data.jsonl # Training data in JSONL format
â”œâ”€â”€ embeddings/             # FAISS index and metadata
â”‚   â”œâ”€â”€ faiss.index        # FAISS vector index
â”‚   â”œâ”€â”€ meta.json          # Index metadata
â”‚   â””â”€â”€ rows.json          # Row mappings
â”œâ”€â”€ scripts/                # Dataset building, evaluation utilities
â”‚   â”œâ”€â”€ build_dataset.py   # Dataset preparation
â”‚   â”œâ”€â”€ evaluate.py        # Model evaluation
â”‚   â”œâ”€â”€ rebuild_embeddings.py  # Rebuild FAISS index
â”‚   â””â”€â”€ test_server.py     # Server testing
â”œâ”€â”€ train/                  # Training scripts and configuration
â”‚   â””â”€â”€ train_lora.py      # LoRA/QLoRA training script
â”œâ”€â”€ infer/                  # Inference server
â”‚   â””â”€â”€ server.py          # FastAPI inference server
â”œâ”€â”€ config/                 # Configuration files
â”‚   â”œâ”€â”€ paths.yaml         # Path configurations
â”‚   â”œâ”€â”€ search.yaml        # Search parameters
â”‚   â””â”€â”€ training.yaml      # Training hyperparameters
â”œâ”€â”€ README.md              # This file
â””â”€â”€ SETUP.md               # Environment setup guide
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.10+
- CUDA 11.8+ (for GPU training) or CPU fallback
- Required packages: `torch`, `transformers`, `datasets`, `peft`, `accelerate`, `bitsandbytes` (if CUDA), `sentencepiece`, `pillow`, `scikit-learn`, `fastapi`, `uvicorn`

### Installation

```bash
# Create conda environment (recommended)
conda create -n ucost-gemma python=3.10
conda activate ucost-gemma

# Install dependencies
pip install torch transformers datasets peft accelerate sentencepiece pillow scikit-learn fastapi uvicorn

# For GPU support (optional)
pip install bitsandbytes
```

### Running the Inference Server

```bash
cd gemma
conda activate ucost-gemma
python infer/server.py --port 8011

# Or use npm from project root
npm run dev:gemma
```

The server will be available at `http://localhost:8011`

## ğŸ“Š Development Milestones

### 1. Dataset Preparation
- Consolidate exhibits from backend DB/JSON
- Extract text, tags, metadata; collect image paths
- Write train/val/test splits, JSONL manifest
- Generate FAISS embeddings for fast search

### 2. Training (LoRA/QLoRA)
- Text-only baseline â†’ instruction-tuned ranking/regression
- Multimodal: add image encoder (CLIP/ViT) with projection to Gemma hidden size
- Objective: pairwise ranking + score regression
- Use QLoRA for 2B model on single GPU
- Mixed precision (fp16/bf16) when supported

### 3. Evaluation
- Hit-rate@K, NDCG, MAP metrics
- Qualitative checks by interest prompts
- A/B testing with real user interactions

### 4. Inference Service
- Export adapter + tokenizer
- Provide HTTP API: `/recommend`
- FAISS-based fast retrieval
- Logistic reranking for quality

## ğŸ”§ Configuration

### Training Configuration (`config/training.yaml`)
- Model: Gemma 2B
- Fine-tuning: LoRA/QLoRA
- Learning rate, batch size, epochs
- Mixed precision settings

### Search Configuration (`config/search.yaml`)
- FAISS index parameters
- Top-K retrieval settings
- Reranking thresholds
- Similarity metrics

## ğŸ“¡ API Endpoints

### `/recommend`
- **Method**: POST
- **Body**: 
  ```json
  {
    "query": "interactive science exhibits for kids",
    "top_k": 5,
    "filters": {
      "category": "physics",
      "floor": "first"
    }
  }
  ```
- **Response**: 
  ```json
  {
    "recommendations": [
      {
        "exhibit_id": "...",
        "score": 0.92,
        "reason": "..."
      }
    ]
  }
  ```

## ğŸ§ª Testing

```bash
# Test the server
python scripts/test_server.py

# Evaluate model performance
python scripts/evaluate.py

# Rebuild embeddings
python scripts/rebuild_embeddings.py
```

## ğŸ“š Documentation

- **SETUP.md**: Detailed environment setup and model weights
- **Root README.md**: High-level overview and integration guide
- **Code comments**: Inline documentation in all scripts

## ğŸ”® Future Enhancements

- [ ] Real-time learning from user feedback
- [ ] Multi-lingual support (Hindi + English)
- [ ] Explainable recommendations
- [ ] A/B testing framework
- [ ] Model versioning and rollback

