{
  "metrics": {
    "total_tests": 7,
    "average_precision": 0.1476190476190476,
    "average_recall": 0.39999999999999997,
    "average_f1_score": 0.1974025974025974,
    "average_accuracy": 0.8508771929824561,
    "average_mrr": 0.2857142857142857,
    "average_coverage": 0.39999999999999997,
    "average_interest_match": 0.6152380952380953
  },
  "test_results": [
    {
      "test_name": "AI and Robotics Interest Match",
      "metrics": {
        "precision": 0.0,
        "recall": 0.0,
        "f1_score": 0.0,
        "accuracy": 0.8245614035087719,
        "mrr": 0.0,
        "coverage": 0.0,
        "tp": 0,
        "fp": 15,
        "fn": 5,
        "tn": 94,
        "interest_match": 1.0
      },
      "recommended_count": 15
    },
    {
      "test_name": "Physics Interest Match",
      "metrics": {
        "precision": 0.06666666666666667,
        "recall": 0.2,
        "f1_score": 0.1,
        "accuracy": 0.8421052631578947,
        "mrr": 0.16666666666666666,
        "coverage": 0.2,
        "tp": 1,
        "fp": 14,
        "fn": 4,
        "tn": 95,
        "interest_match": 0.9333333333333333
      },
      "recommended_count": 15
    },
    {
      "test_name": "Astronomy and Space Interest Match",
      "metrics": {
        "precision": 0.0,
        "recall": 0.0,
        "f1_score": 0.0,
        "accuracy": 0.9035087719298246,
        "mrr": 0.0,
        "coverage": 0.0,
        "tp": 0,
        "fp": 6,
        "fn": 5,
        "tn": 103,
        "interest_match": 0.6666666666666666
      },
      "recommended_count": 6
    },
    {
      "test_name": "Technology and Innovation Interest Match",
      "metrics": {
        "precision": 0.2,
        "recall": 0.6,
        "f1_score": 0.3,
        "accuracy": 0.8771929824561403,
        "mrr": 1.0,
        "coverage": 0.6,
        "tp": 3,
        "fp": 12,
        "fn": 2,
        "tn": 97,
        "interest_match": 1.0
      },
      "recommended_count": 15
    },
    {
      "test_name": "Family-Friendly Exhibits",
      "metrics": {
        "precision": 0.0,
        "recall": 0.0,
        "f1_score": 0.0,
        "accuracy": 0.9122807017543859,
        "mrr": 0.0,
        "coverage": 0.0,
        "tp": 0,
        "fp": 5,
        "fn": 5,
        "tn": 104,
        "interest_match": 0.0
      },
      "recommended_count": 5
    },
    {
      "test_name": "Space-And-Astronomy Category Match",
      "metrics": {
        "precision": 0.6666666666666666,
        "recall": 1.0,
        "f1_score": 0.8,
        "accuracy": 0.9912280701754386,
        "mrr": 0.5,
        "coverage": 1.0,
        "tp": 2,
        "fp": 1,
        "fn": 0,
        "tn": 111,
        "interest_match": 0.6666666666666666
      },
      "recommended_count": 3
    },
    {
      "test_name": "General Recommendations",
      "metrics": {
        "precision": 0.1,
        "recall": 1.0,
        "f1_score": 0.18181818181818182,
        "accuracy": 0.6052631578947368,
        "mrr": 0.3333333333333333,
        "coverage": 1.0,
        "tp": 5,
        "fp": 45,
        "fn": 0,
        "tn": 64,
        "interest_match": 0.04
      },
      "recommended_count": 50
    }
  ]
}